{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steering Control for Udacity simulater using Deep learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#import modules\n",
    "import numpy as np\n",
    "import keras\n",
    "import csv\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the file directory for training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_directory = './train_data/'\n",
    "labels_file= './train_data/driving_log.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre processing the image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use 32*64 as the input layer dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = 32\n",
    "cols = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre processing the image includes\n",
    "1. cropping of the top and bottom of the frame since this is not useful for predictin the steering angle\n",
    "2. resize and normalize the images\n",
    "    Here only the S channel of the HSV image is used to reduce the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#proprocess: change to HSV space and resize\n",
    "def preprocess(img, top_offset=.375, bottom_offset=.125):\n",
    "    \"\"\"\n",
    "    Applies preprocessing pipeline to an image: crops `top_offset` and `bottom_offset`\n",
    "    portions of image, resizes to 32x128 px and scales pixel values to [0, 1].\n",
    "    \"\"\"\n",
    "    top = int(top_offset * img.shape[0])\n",
    "    bottom = int(bottom_offset * img.shape[0])\n",
    "    resized = cv2.resize((cv2.cvtColor(img[top:-bottom, :], cv2.COLOR_RGB2HSV))[:,:,1],(cols,rows))\n",
    "    return resized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function defintion to save model.json & model_h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_save(model_json,model_h5):\n",
    "    json_model = model.to_json()\n",
    "    with open(model_json, \"w\") as f:\n",
    "        f.write(json_model)\n",
    "    model.save_weights(model_h5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data: steering tags and the  left, center & right camera "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The images from the left and right camera is also part of the training set. But only the center camera takes for prediction. For the input data we use the data provided by Udacity and add our training data by riding around the simulator circuit. \n",
    "\n",
    "Since the track didnt emulate shadows we randomly added shadows to the image vertically.\n",
    "For each tag read from the input csv file the corresponding  image files are read. For the left and right cameras we give a steering offset of +/- delta to account for the difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loading(delta):\n",
    "    logs = []\n",
    "    features = []\n",
    "    labels = []\n",
    "    augment = 1\n",
    "    with open(labels_file,'rt') as f:\n",
    "        temp = 0\n",
    "        reader = csv.reader(f)\n",
    "        \n",
    "        for line in reader:\n",
    "            logs.append(line)\n",
    "        log_labels = logs.pop(0)\n",
    "        shadow_indices = np.random.choice(2, len(logs), replace=True, p=[0.80, 0.20])\n",
    "        for i in range(len(logs)):\n",
    "        \n",
    "            for j in range(3):\n",
    "                img_path = logs[i][j]                    \n",
    "                \n",
    "\n",
    "                img_path = features_directory+'IMG'+(img_path.split('IMG')[1]).strip()\n",
    "                img = plt.imread(img_path)    \n",
    "                if augment:\n",
    "                    # Add random shadow as a vertical slice of image\n",
    "                    h, w = img.shape[0], img.shape[1]\n",
    "                    [x1, x2] = np.random.choice(w, 2, replace=False)\n",
    "                    k = h / (x2 - x1)\n",
    "                    b = - k * x1\n",
    "                    for row in range(h):\n",
    "                        col = int((row - b) / k)\n",
    "                        img.setflags(write=1)\n",
    "                        img[row, :col, :] = (img[row, :col, :] * .5).astype(np.int32)\n",
    "                features.append(preprocess(img))\n",
    "                if j == 0:\n",
    "                    labels.append(float(logs[i][3]))\n",
    "                elif j == 1:\n",
    "                    labels.append(float(logs[i][3]) + delta)\n",
    "                else:\n",
    "                    labels.append(float(logs[i][3]) - delta)\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data and transform to numpy array\n",
    "#parameter, defining the shift variable for left and righ steering angle\n",
    "delta = 0.2\n",
    "features, labels = data_loading(delta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert features to array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28437, 32, 64)\n"
     ]
    }
   ],
   "source": [
    "features = np.array(features).astype('float32')\n",
    "labels = np.array(labels).astype('float32')\n",
    "print(features.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create double the training samples by just flipping the images horizontally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56874, 32, 64)\n"
     ]
    }
   ],
   "source": [
    "#augment the data by horizontal flipping the image\n",
    "features = np.append(features,features[:,:,::-1],axis=0)\n",
    "labels = np.append(labels,-labels,axis=0)\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the test and validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle the data and split to train and validation \n",
    "features, labels = shuffle(features, labels)\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, random_state=0, test_size=0.1)\n",
    "\n",
    "#reshape the data  to feed into the network\n",
    "train_features = train_features.reshape(train_features.shape[0], rows, cols, 1)\n",
    "test_features = test_features.reshape(test_features.shape[0], rows, cols, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model has 3 convolution layers and 3 fully connected layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the model\n",
    "def steering_model():\n",
    "    model = Sequential()\n",
    "    model.add(Lambda(lambda x: x/127.5 - 1.,input_shape=(rows,cols,1)))\t\n",
    "\n",
    "    model.add(Convolution2D(8, 3, 3, init='normal',border_mode='valid'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D((2,2),border_mode='valid'))\n",
    "\n",
    "    model.add(Convolution2D(8, 3, 3,init='normal',border_mode='valid'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D((2,2),border_mode='valid'))\n",
    "    \n",
    "    model.add(Convolution2D(8, 3, 3,init='normal',border_mode='valid'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D((2,2),border_mode='valid'))\n",
    "\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(core.Dropout(.5))\n",
    "    \n",
    "    model.add(Dense(50))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating the model\n",
    "\n",
    "We have used the standard Adam optimizer as in our labs with a leraning rate of 0.001.\n",
    "\n",
    "For training and fitting the model we use a Batch size of 128 and number we utilized a couple of epochs but found that more than 15 there is no considerable difference in the performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\denny\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(8, (3, 3), kernel_initializer=\"normal\", padding=\"valid\")`\n",
      "  \n",
      "c:\\users\\denny\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D((2, 2), padding=\"valid\")`\n",
      "  \n",
      "c:\\users\\denny\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(8, (3, 3), kernel_initializer=\"normal\", padding=\"valid\")`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "c:\\users\\denny\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:12: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D((2, 2), padding=\"valid\")`\n",
      "  if sys.path[0] == '':\n",
      "c:\\users\\denny\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(8, (3, 3), kernel_initializer=\"normal\", padding=\"valid\")`\n",
      "  \n",
      "c:\\users\\denny\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:16: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D((2, 2), padding=\"valid\")`\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lambda_4 (Lambda)            (None, 32, 64, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 30, 62, 8)         80        \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 30, 62, 8)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 15, 31, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 13, 29, 8)         584       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 13, 29, 8)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 6, 14, 8)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 4, 12, 8)          584       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 4, 12, 8)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 2, 6, 8)           0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 2, 6, 8)           0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 96)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 100)               9700      \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 16,049\n",
      "Trainable params: 16,049\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 51186 samples, validate on 5688 samples\n",
      "Epoch 1/11\n",
      "51186/51186 [==============================] - 53s - loss: 0.0258 - val_loss: 0.0210\n",
      "Epoch 2/11\n",
      "51186/51186 [==============================] - 51s - loss: 0.0216 - val_loss: 0.0207\n",
      "Epoch 3/11\n",
      "51186/51186 [==============================] - 51s - loss: 0.0209 - val_loss: 0.0199\n",
      "Epoch 4/11\n",
      "51186/51186 [==============================] - 51s - loss: 0.0205 - val_loss: 0.0200\n",
      "Epoch 5/11\n",
      "51186/51186 [==============================] - 51s - loss: 0.0201 - val_loss: 0.0194\n",
      "Epoch 6/11\n",
      "51186/51186 [==============================] - 51s - loss: 0.0197 - val_loss: 0.0195\n",
      "Epoch 7/11\n",
      "51186/51186 [==============================] - 52s - loss: 0.0196 - val_loss: 0.0191\n",
      "Epoch 8/11\n",
      "51186/51186 [==============================] - 50s - loss: 0.0194 - val_loss: 0.0192\n",
      "Epoch 9/11\n",
      "51186/51186 [==============================] - 50s - loss: 0.0192 - val_loss: 0.0196\n",
      "Epoch 10/11\n",
      "51186/51186 [==============================] - 51s - loss: 0.0191 - val_loss: 0.0191\n",
      "Epoch 11/11\n",
      "51186/51186 [==============================] - 49s - loss: 0.0189 - val_loss: 0.0190\n",
      "Saved model to  ./model.json\n"
     ]
    }
   ],
   "source": [
    "#optimize\n",
    "model = steering_model()\n",
    "adam = Adam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "model.compile(loss='mean_squared_error',optimizer='adam')\n",
    "history = model.fit(train_features, train_labels,batch_size=128, epochs=11,verbose=1, validation_data=(test_features, test_labels))\n",
    "\n",
    "#save the model architecture and parameters\n",
    "model_json = './model.json'\n",
    "model_h5 = './model.h5'\n",
    "model_save(model_json,model_h5)\n",
    "print (\"Saved model to \", model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
